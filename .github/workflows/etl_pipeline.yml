name: ETL Pipeline

on:
  push:
    paths:
      - 'Retail_DataLakeHouse/**'
  pull_request:
    paths:
      - 'Retail_DataLakeHouse/**'
  schedule:
    - cron: '30 0 * * *'  # Runs daily at 6 AM IST (0:30 UTC)

jobs:
  etl:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r Retail_DataLakeHouse/requirements.txt

      - name: Run ETL scripts
        run: |
          python Retail_DataLakeHouse/generate_retail_data.py
          python Retail_DataLakeHouse/ingest_data.py
          python Retail_DataLakeHouse/transform_data.py

      - name: Run ETL tests
        run: |
          python Retail_DataLakeHouse/etl_test.py

      - name: Install dbt
        run: |
          pip install dbt-core dbt-sqlite

      - name: Create dbt profile
        run: |
          mkdir -p ~/.dbt
          mkdir -p $(pwd)/Retail_DataLakeHouse/data
          echo 'retail_dbt:' > ~/.dbt/profiles.yml
          echo '  target: dev' >> ~/.dbt/profiles.yml
          echo '  outputs:' >> ~/.dbt/profiles.yml
          echo '    dev:' >> ~/.dbt/profiles.yml
          echo '      type: sqlite' >> ~/.dbt/profiles.yml
          echo '      threads: 1' >> ~/.dbt/profiles.yml
          echo "      database: '$(pwd)/Retail_DataLakeHouse/data/retail_dwh.db'" >> ~/.dbt/profiles.yml
          echo '      schema: main' >> ~/.dbt/profiles.yml
          echo "      schema_directory: '$(pwd)/Retail_DataLakeHouse/data/'" >> ~/.dbt/profiles.yml
          echo '      schemas_and_paths:' >> ~/.dbt/profiles.yml
          echo "        main: '$(pwd)/Retail_DataLakeHouse/data/retail_dwh.db'" >> ~/.dbt/profiles.yml

      - name: Clean existing SQLite DB
        run: |
          rm -f Retail_DataLakeHouse/data/retail_dwh.db

      - name: Load CSV into SQLite
        run: |
          python - <<EOF
          import pandas as pd, sqlite3, os
          db_path = os.path.join("Retail_DataLakeHouse", "data", "retail_dwh.db")
          os.makedirs(os.path.dirname(db_path), exist_ok=True)
          conn = sqlite3.connect(db_path)
          csv_path = os.path.join("Retail_DataLakeHouse", "data", "sales_2025_01_01.csv")
          if not os.path.exists(csv_path):
              raise FileNotFoundError(f"❌ CSV not found at: {csv_path}")
          df = pd.read_csv(csv_path)
          df.to_sql("main.sales_2025_01_01", conn, index=False, if_exists="replace")
          conn.close()
          print("✅ Loaded sales_2025_01_01.csv into SQLite database successfully.")
          EOF

      - name: Run dbt models
        run: |
          cd Retail_DataLakeHouse/retail_dbt
          dbt deps
          dbt run --profiles-dir ~/.dbt
          dbt test --profiles-dir ~/.dbt
